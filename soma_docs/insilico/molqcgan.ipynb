{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from orquestra.qml.models.samplers.th import MultiDimGaussianSampler\n",
    "from orquestra.qml.trainers import AdversarialTrainer\n",
    "\n",
    "from utils import SmilesEncoding\n",
    "from models.gan.molqcgan import MolGenerator, MolDiscriminator, MolQCGAN, sample_from_mol_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"data/selfies_smiles_scores_KRAS.csv\"\n",
    "dataset_id = \"insilico_KRAS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = SmilesEncoding(\n",
    "    path_to_dataset,\n",
    "    dataset_identifier=dataset_id\n",
    ")\n",
    "\n",
    "sequence_length = smiles.max_length\n",
    "sample_dimension = 10\n",
    "vocab_size = smiles.num_emd\n",
    "padding_idx = smiles.pad_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = MultiDimGaussianSampler((sequence_length, sample_dimension))\n",
    "\n",
    "# NOTE: MolGenerator samples need to be passed through a softmax layer to get probabilities and then sampled from to get the actual encoded SMILES\n",
    "generator = MolGenerator(\n",
    "    noise_dim=sample_dimension,\n",
    "    sequence_length=sequence_length,\n",
    "    vocab_size=vocab_size,\n",
    "    output_activation=torch.nn.Identity()  # we use identity because we want raw logits that get fed to discriminator\n",
    "    \n",
    ")\n",
    "discriminator = MolDiscriminator(\n",
    "    vocab_size=vocab_size,\n",
    "    latent_dim=64,\n",
    "    sequence_length=sequence_length,\n",
    "    padding_index=padding_idx\n",
    ")\n",
    "\n",
    "mol_gan = MolQCGAN(generator, discriminator, prior)\n",
    "# mol_gan.to_device(torch.device(\"mps:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = smiles.create_data_loader(batch_size=32)\n",
    "data_loader.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AdversarialTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cache = trainer.train(mol_gan, data_loader, n_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_samples = mol_gan.generate(10)\n",
    "encoded_samples = sample_from_mol_logits(logit_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles.decode_smiles(encoded_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insilico-dd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82d614cf616057cc9a5f4c6e14402d580af78b0c9119570cd74050e1a910c20b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
