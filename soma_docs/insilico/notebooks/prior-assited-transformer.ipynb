{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamad/workspace/repos/insilico-drug-discovery/notebooks/../utils/filter.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Chem.MolFromSmarts(x) for x in _mcf.append(_pains, sort=True)[\"smarts\"].values\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import tqdm\n",
    "import torch\n",
    "from orquestra.qml.models.rbm.th import RBM, TrainingParameters as RBMParams\n",
    "import sys,os\n",
    "sys.path.append(os.path.join(\"../\"))\n",
    "from utils import Experiment, SelfiesEncoding\n",
    "from models import MolPAT\n",
    "from pathlib import Path\n",
    "from orquestra.qml.data_loaders import new_data_loader\n",
    "from orquestra.qml.api import (\n",
    "    TorchGenerativeModel,\n",
    "    GenerativeModel,\n",
    "    Callback,\n",
    "    TrainCache,\n",
    "    convert_to_numpy,\n",
    "    GenerativeModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(run_id=MolPAT-2023_23_03T18_22, path=/Users/mohamad/workspace/repos/insilico-drug-discovery/notebooks/experiment_results/MolPAT-2023_23_03T18_22)\n"
     ]
    }
   ],
   "source": [
    "run_date_time = datetime.today().strftime(\"%Y_%d_%mT%H_%M\")\n",
    "experiment = Experiment(run_id=f\"MolPAT-{run_date_time}\")\n",
    "print(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL EXPERIMENT VARIABLES\n",
    "experiment.path_to_dataset = \"../data/KRAS_G12D/KRAS_G12D_inhibitors_update2023.csv\"\n",
    "experiment.dataset_id = \"insilico_KRAS\"\n",
    "\n",
    "# TRAINING VARIABLES\n",
    "experiment.n_epochs = 1\n",
    "experiment.batch_size = 32\n",
    "experiment.seed = 1000\n",
    "experiment.set(n_prior_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the SMILES or SELFIES object\n",
    "selfies = SelfiesEncoding(\n",
    "    experiment.path_to_dataset,\n",
    "    dataset_identifier=experiment.dataset_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can add function to RBM to return the configuration\n",
    "prior = RBM(\n",
    "    n_visible_units=10, \n",
    "    n_hidden_units=10, \n",
    "    training_parameters=RBMParams()\n",
    ")\n",
    "\n",
    "prior_config = dict(\n",
    "    name=prior.name,\n",
    "    n_visible_units=prior.n_visible_units,\n",
    "    n_hidden_units=prior.n_hidden_units,\n",
    "    training_parameters=prior.training_parameters.__dict__\n",
    ")\n",
    "\n",
    "experiment.model_configurations.append(prior_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MolPAT(\n",
    "    vocab_size=selfies.num_emd,\n",
    "    seq_len=selfies.max_length,\n",
    "    start_token_index=selfies.start_char_index,\n",
    "    prior_dim=prior.sample_size[-1],\n",
    "    padding_token_index=selfies.pad_char_index,\n",
    "    hidden_dim=128,\n",
    "    embedding_dim=256,\n",
    ")\n",
    "\n",
    "experiment.model_configurations.append(model.config.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape\n",
      "==============================================================================================================\n",
      "_DiscretePATModel                                            --                        --\n",
      "├─TransformerEncoder (encoder): 1                            --                        --\n",
      "│    └─ModuleList (layers): 2-1                              --                        --\n",
      "├─Embedding (embedding): 1-1                                 [1, 835]                  [1, 835, 256]\n",
      "├─Concatenate (concatenate): 1-2                             [1, 835, 256]             [1, 835, 266]\n",
      "├─Linear (pre_pe_projection): 1-3                            [1, 835, 266]             [1, 835, 128]\n",
      "├─PositionalEncoding (positional_encoding): 1-4              [1, 835, 128]             [1, 835, 128]\n",
      "│    └─Dropout (dropout): 2-2                                [1, 835, 128]             [1, 835, 128]\n",
      "├─TransformerEncoder (encoder): 1                            --                        --\n",
      "│    └─ModuleList (layers): 2-3                              --                        --\n",
      "├─TransformerEncoder (encoder): 1-5                          [1, 835, 128]             [1, 835, 128]\n",
      "│    └─ModuleList (layers): 2-1                              --                        --\n",
      "│    │    └─TransformerEncoderLayer (0): 3-1                 [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─MultiheadAttention (self_attn): 4-1         [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─Dropout (dropout1): 4-2                     [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─LayerNorm (norm1): 4-3                      [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─Linear (linear1): 4-4                       [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─LayerNorm (norm1): 4-5                      --                        --\n",
      "│    │    │    └─LayerNorm (norm2): 4-6                      --                        --\n",
      "│    │    │    └─ReLU (activation): 4-7                      [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─Dropout (dropout): 4-8                      [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─Linear (linear2): 4-9                       [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─Dropout (dropout2): 4-10                    [1, 835, 128]             [1, 835, 128]\n",
      "│    │    │    └─LayerNorm (norm2): 4-11                     [1, 835, 128]             [1, 835, 128]\n",
      "├─Linear (output_head): 1-6                                  [1, 835, 128]             [1, 835, 34]\n",
      "├─LogSoftmax (output_activation_fn): 1-7                     [1, 835, 34]              [1, 835, 34]\n",
      "==============================================================================================================\n",
      "Total params: 80,802\n",
      "Trainable params: 80,802\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.08\n",
      "==============================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 6.21\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 6.54\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "dummy_input_data = torch.zeros((1, model.seq_len)).long()\n",
    "dummy_prior_samples = prior.generate(1).float()\n",
    "model.summary(input_data=(dummy_input_data, dummy_prior_samples), col_names=[\"input_size\", \"output_size\"], depth=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = prior.generate(5).float()\n",
    "mols = model.generate(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "n_test_samples = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples_th = torch.tensor(selfies.encoded_samples)\n",
    "data = encoded_samples_th.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_plot_dir = Path(\"experiment_results\") / \"epoch_plots\" / experiment.run_id\n",
    "epoch_plot_dir = epoch_plot_dir.resolve()\n",
    "\n",
    "if epoch_plot_dir.exists() is False:\n",
    "    os.makedirs(str(epoch_plot_dir))\n",
    "\n",
    "\n",
    "dataloader = new_data_loader(\n",
    "    data=data, batch_size = batch_size\n",
    ").shuffle(12345)\n",
    "train_cache = TrainCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_compunds = {}\n",
    "live_model_loss = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    with tqdm.tqdm(total=dataloader.n_batches) as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch} / {n_epochs}.\")\n",
    "        concat_prior_samples = []\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            prior_samples = prior.generate(batch.batch_size).long()\n",
    "            batch.targets = prior_samples\n",
    "            batch_result = model.train_on_batch(batch)\n",
    "            train_cache.update_history(batch_result)\n",
    "            concat_prior_samples = concat_prior_samples + prior_samples.tolist()\n",
    "\n",
    "            pbar.set_postfix(dict(Loss=batch_result[\"loss\"]))\n",
    "            pbar.update()\n",
    "            # if torch.cuda.is_available():\n",
    "            #     torch.cuda.empty_cache()\n",
    "        th_prior_samples = torch.tensor(concat_prior_samples)\n",
    "        # put model in evaluation mode such that layers like Dropout, Batchnorm don't affect results\n",
    "        model.set_eval_state()\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_train_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "P0 = prior.generate(1).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = model.generate(P0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1COC(=C)C2CC1(C(=C)N=C(C2C3C)Br)CN=C3(CC[C@@H](F))']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfies.decode_fn(S0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drugdiscovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90f791b1cfe986cfa1bf816a7669520be59f4dde95a0c6013dec308e7178b635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
